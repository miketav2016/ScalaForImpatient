https://github.com/scala/scala-parallel-collections


If parallel computations mutate shared variables, the result is unpredictable. For example, do
not update a shared counter:
Click here to view code image
var count = 0
for (c <- coll.par) { if (c % 2 == 0) count += 1 } // Error!
You can convert a parallel collection back to a sequential one with the seq method.
val result = coll.par.filter(p).seq
Not all methods can be parallelized. For example, reduceLeft and reduceRight require that
each operator is applied in sequence. There is an alternate method, reduce, that operates on parts of
the collection and combines the results. For this to work, the operator must be associative—it must
fulfill (a op b) op c = a op (b op c). For example, addition is associative but subtraction is not: (a –
b) – c ≠ a – (b – c).
Similarly, there is a fold method that operates on parts of the collection. Unfortunately, it is not as
flexible as foldLeft or foldRight—both arguments of the operator must be elements. That is,
you can do coll.par.fold(0)(_ + _)
To solve this problem, there is an even more general aggregate that applies an operator to parts
of the collection, and then uses another operator to combine the results. For example,
str.par.aggregate(Set[Char]())(_ + _, _ ++ _) is the equivalent of
str.foldLeft(Set[Char]())(_ + _), forming a set of all distinct characters in str.
By default, parallel collections use a global fork-join pool, which is well suited for processorintensive calculations. If you carry out parallel computation steps that block, you should choose
a different “execution context”